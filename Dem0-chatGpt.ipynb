{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42d00139",
   "metadata": {},
   "source": [
    "# ChatGpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7faf8b",
   "metadata": {},
   "source": [
    "Based on [this](https://github.com/santiagobasulto/ipython-gpt/blob/master/Demo.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5979da73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipython-gpt in /home/luis/anaconda3/lib/python3.8/site-packages (0.0.6)\n",
      "Requirement already satisfied: ipython<9.0.0,>=8.12.0 in /home/luis/anaconda3/lib/python3.8/site-packages (from ipython-gpt) (8.12.2)\n",
      "Requirement already satisfied: backcall in /home/luis/anaconda3/lib/python3.8/site-packages (from ipython<9.0.0,>=8.12.0->ipython-gpt) (0.2.0)\n",
      "Requirement already satisfied: decorator in /home/luis/anaconda3/lib/python3.8/site-packages (from ipython<9.0.0,>=8.12.0->ipython-gpt) (5.1.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/luis/anaconda3/lib/python3.8/site-packages (from ipython<9.0.0,>=8.12.0->ipython-gpt) (0.17.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/luis/anaconda3/lib/python3.8/site-packages (from ipython<9.0.0,>=8.12.0->ipython-gpt) (0.1.2)\n",
      "Requirement already satisfied: pickleshare in /home/luis/anaconda3/lib/python3.8/site-packages (from ipython<9.0.0,>=8.12.0->ipython-gpt) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /home/luis/anaconda3/lib/python3.8/site-packages (from ipython<9.0.0,>=8.12.0->ipython-gpt) (3.0.38)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/luis/anaconda3/lib/python3.8/site-packages (from ipython<9.0.0,>=8.12.0->ipython-gpt) (2.10.0)\n",
      "Requirement already satisfied: stack-data in /home/luis/anaconda3/lib/python3.8/site-packages (from ipython<9.0.0,>=8.12.0->ipython-gpt) (0.6.2)\n",
      "Requirement already satisfied: traitlets>=5 in /home/luis/anaconda3/lib/python3.8/site-packages (from ipython<9.0.0,>=8.12.0->ipython-gpt) (5.1.0)\n",
      "Requirement already satisfied: typing-extensions in /home/luis/anaconda3/lib/python3.8/site-packages (from ipython<9.0.0,>=8.12.0->ipython-gpt) (3.10.0.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/luis/anaconda3/lib/python3.8/site-packages (from ipython<9.0.0,>=8.12.0->ipython-gpt) (4.8.0)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /home/luis/anaconda3/lib/python3.8/site-packages (from jedi>=0.16->ipython<9.0.0,>=8.12.0->ipython-gpt) (0.7.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/luis/anaconda3/lib/python3.8/site-packages (from pexpect>4.3->ipython<9.0.0,>=8.12.0->ipython-gpt) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/luis/anaconda3/lib/python3.8/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython<9.0.0,>=8.12.0->ipython-gpt) (0.2.5)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/luis/anaconda3/lib/python3.8/site-packages (from stack-data->ipython<9.0.0,>=8.12.0->ipython-gpt) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/luis/anaconda3/lib/python3.8/site-packages (from stack-data->ipython<9.0.0,>=8.12.0->ipython-gpt) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /home/luis/anaconda3/lib/python3.8/site-packages (from stack-data->ipython<9.0.0,>=8.12.0->ipython-gpt) (0.2.2)\n",
      "Requirement already satisfied: six in /home/luis/anaconda3/lib/python3.8/site-packages (from asttokens>=2.1.0->stack-data->ipython<9.0.0,>=8.12.0->ipython-gpt) (1.16.0)\n",
      "\u001b[33mWARNING: Error parsing requirements for matplotlib: [Errno 2] No such file or directory: '/home/luis/anaconda3/lib/python3.8/site-packages/matplotlib-3.3.4.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install ipython-gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a061f930",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext ipython_gpt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8a2e5e",
   "metadata": {},
   "source": [
    "\n",
    "#### Setup\n",
    "\n",
    "You must first generate an API key at OpenAI (https://platform.openai.com/account/api-keys) and set is an environment variable OPENAI_API_KEY. You can do it by modifying your .bashrc/.zshrc or starting jupyter with it:\n",
    "\n",
    "$ OPENAI_API_KEY=[YOUR-KEY] jupyter lab\n",
    "\n",
    "There are a few other ways to set the API KEY, but the envvar is the recommended one.\n",
    "\n",
    "#### ChatGPT API\n",
    "\n",
    "The command %%chat interfaces with ChatGPT. It accepts multiple parameters (see Usage). Here's an example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35fb1bbd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "OPENAI_API_KEY missing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m--max-tokens=25\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mWhat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms the purpose of life?\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:2478\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2476\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2477\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2478\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2480\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2481\u001b[0m \u001b[38;5;66;03m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2482\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ipython_gpt/__init__.py:27\u001b[0m, in \u001b[0;36mIPythonGPT.chat\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@cell_magic\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchat\u001b[39m(\u001b[38;5;28mself\u001b[39m, line, cell):\n\u001b[1;32m     26\u001b[0m     cmd \u001b[38;5;241m=\u001b[39m ChatCommand(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context)\n\u001b[0;32m---> 27\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mcmd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mdisplay(result)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ipython_gpt/subcommands.py:50\u001b[0m, in \u001b[0;36mBaseIPythonGPTCommand.execute\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# TODO: Add logging (and new argument --debug)\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# if debug: logger.log()\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# TODO: Look for a way to refactor args and config. Smells\u001b[39;00m\n\u001b[1;32m     49\u001b[0m openai_api_key \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mopenai_api_key \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai_api_key\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 50\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(openai_api_key), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY missing\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     51\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAIClient(openai_api_key)\n\u001b[1;32m     52\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute(client, args, line, cell)\n",
      "\u001b[0;31mAssertionError\u001b[0m: OPENAI_API_KEY missing"
     ]
    }
   ],
   "source": [
    "%%chat --max-tokens=25\n",
    "\n",
    "What's the purpose of life?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbea3ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
